## SETUP

Run python install -r requirements.txt

Run python -m spacy download en_core_web_sm

nltk.download('punkt') in data_extraction.py may download and check for update for every run


## RUNNING THE CODE

### SENTIMENT CODE

In sentiment.py the sentiment function can be used by passing in the data file, such as gg2013.json, and the output dictionary for the main code.


### MAIN CODE

All codes and files that are necessary for running autograder are in the data_extraction directory. To run the autograder, first, make sure the preprocessed JSON data from IMDB for a specific year is in the data_extraction/data/ directory, and run main() in gg_api.py to compute the answer for a specific year into a JSON file. All function calls in gg_api.py except get_awards() uses the answer JSON file (i.e. 2013_award_extraction_answer.json). The purpose is to save computation.

For example, to run 2013 data, firstly unzip Tweets data (gg2013.zip and gg2015.zip). Check the preprocessed IMDB data: data_extraction/data/2013_title_data.json and data_extraction/data/2013_name_data.json, which may also be computed through IMDB_Processor.select_from_database() in data_processing.py from IMDB's original data (www.imdb.com/interfaces/). IMDB's original data should be placed in data_extraction/data/ directory as well. Then, make sure data_extraction/2013_award_extraction_answer.json is generated by running main() in gg_api.py. Run autograder.py should work after that.

Library used are included in requirements.txt.
